---
title: "PracticalMachineLearning_ROBMILL_Mac"
output: html_document
---
### Final Peer Reviewed Assignment
## Practical Machine Learning
## Week 4

```{r preparation, include=FALSE}
# Load Librarys
# Load Data
library(kernlab)
library(caret)
library(ggplot2)
library(Hmisc)
library(gridExtra)
library(graphics)
library(klaR)
library(gbm)
library(e1071)
library(MASS)
library(plyr)

#training<-read.csv(file = "pml-training.csv",stringsAsFactors #= FALSE) # Read training data

#exerciseData<-read.csv(file = "pml-training.csv") # Read training data

#validation<-read.csv(file = "pml-testing1.csv") # Read testing data

#   Establish & Create Data Directory
if (!file.exists("./data")) { dir.create("./data") }

#   Retrieve and Load Training DataSet
trainURL  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
    trainCSV  <- "./data/pml-training.csv"
    if (!file.exists(trainCSV)) {download.file( trainURL, destfile=trainCSV)}
    exerciseData  <- read.csv(trainCSV, na.strings=c("NA",""), header=TRUE)

#   Retrieve and Load Testing DataSet
    testURL   <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
    testCSV   <- "./data/pml-testing.csv"
    if (!file.exists(testCSV)) {download.file( testURL, destfile=testCSV)}
    validation    <- read.csv(testCSV, na.strings=c("NA",""), header=TRUE)

dim(exerciseData)
```
# Synopsis

Data source for reproducibility:
1.  <http://groupware.les.inf.puc-rio.br/har>
2.  <http://groupware.les.inf.puc-rio.br/har#weight_lifting_exercises>

The data set describes quality of execution for the device wearer while doing dumbbell lift exercises.  

There are 5 different classes representing execution quality.  Class A represents an example of successful execution of the exercise while Classes B-E represent examples of common mistakes made.  

* Class A: exactly according to specification.
* Class B: throwing the elbows to the front.
* Class C: lifting the dumbell only halfway.
* Class D: lowering dumbell only halfway.
* Class E: throwing the hips to the front.

### The goal of the exercise is to identify predictors that accurately determine execution quality or manner of exercise.

### Three separate modeling approaches were applied:
1. Naive Bayes: to act as a benchmark for classification performance.
2. Classification Trees: EDA presents some break opportunities for total_accel features that may lend themselves to a classification tree algorithm.
3. Boosted Machine (GBM): run against data to test for a more accurate modeling approach.

### Out of sample error
* Estimated by testing accuracy of each model against a portion of the exerciseData set.
1. Naive Bayes out of sample error is ~11%.
2. Classification Tree has an out of sample error of ~30%.
3. GBM has an estimated out of sample error of ~.03%.

### Summary of model performance.
1. Naive Bayes predicted all 5 classes of execution quality equally.
2. Classification trees failed to predict classes C and D while A, B, and E were reasonable.  EDA supports this finding.
3. GBM may overfit - and predicts all classes of execution quality equally.  

### Initial EDA on Raw Data Set
```{r EDA }

dim(exerciseData) # display number or rows/columns

head(exerciseData) # display first few rows
table(exerciseData$classe) # display a table using classe


# Density plots
qplot(total_accel_arm,colour=classe,
      data=exerciseData, geom="density")

qplot(total_accel_forearm,colour=classe,
      data=exerciseData,geom="density")

qplot(total_accel_dumbbell,colour=classe,
      data=exerciseData, geom="density")

qplot(total_accel_belt,colour=classe,
      data=exerciseData, geom="density")

featurePlot(x=exerciseData[,c("total_accel_forearm","total_accel_dumbbell","total_accel_belt","total_accel_arm")], 
            y=exerciseData$classe, 
            plot="pairs",
            auto.key=list(columns = 5))
```


### Partition exerciseData Data and Pre-processing
```{r Data Partitioning and Preproc}

  InputDf  <- exerciseData  # cleanse the Training Dataframe
#   Step 1. Remove Variables containing missing or NA values.
    InputDf <- exerciseData
    Step01  <- InputDf[, colSums(is.na(InputDf)) == 0]
    dim(Step01)

#   Step 2. Remove timestamp and window variables that do not describe accelerometer measurements
    target  <- grepl("^X|timestamp|window", names(Step01))
    Step02  <- Step01[, !target]

#   Step 3. Coerce accelerometer measurements (variables) to be numeric
    classe        <- Step02$classe   #Preserve the classe (factor) variable 
    Step03        <- Step02[, sapply(Step02, is.numeric)]
    Step03$classe <- classe   #Join classe to the remaining dataset
    exerciseData   <- Step03

  InputDf  <- validation # cleanse the Testing Dataframe (using the same steps)
#   Step 1. Remove Variables containing missing or NA values.
    Step01  <- InputDf[, colSums(is.na(InputDf)) == 0]

#   Step 2. Remove timestamp and window variables that do not describe accelerometer measurements
    target  <- grepl("^X|timestamp|window", names(Step01))
    Step02  <- Step01[, !target]

#   Step 3. Coerce accelerometer measurements (variables) to be numeric - classe doesn't exist in test
    Step03  <- Step02[, sapply(Step02, is.numeric)]
    validation  <- Step03



inTrain<-createDataPartition(exerciseData$classe,
                             p=0.80,
                             list=FALSE)


training<-exerciseData[inTrain,]
testing<-exerciseData[-inTrain,]

# Display number of rows and columnts 
# in training and testing data sets
dim(training)
dim(testing)

dim(validation)

# Set some alternate Cross-Validation Methods
fitControl <- trainControl(method = "cv", number=3)
fitControl

```


```{r model fitting Naive Bayes, include=FALSE}


# Build benchmark model - Naive Bayes
modFit.NB<-NaiveBayes(classe~., data=training)

# Predict using testing data set
predictions.NB<-predict(modFit.NB,testing)
```

```{r confustion matrix for NB}
# Print accuracy measurements
confusionMatrix(predictions.NB$class,testing$classe)


```
### Classification Tree using a Boosting cross-validation TrainControl

```{r model fitting Classification Tree, include=FALSE}

# Train a model 
modFit.rpart<-train(classe~.,data=training,
                     method="rpart",trControl=fitControl)


```

```{r CT predictions}
# Predict using CT model
predictions.rpart<-predict(modFit.rpart,testing)

```

```{r CT confusion matrix}
# Print accuracy measurements
confusionMatrix(predictions.rpart,testing$classe)


```


### Run a Boosting Algorithm against all features

```{r model fitting GBM, include=FALSE}
# Train a model using RF
modFit.boost<-train(classe~.,method="gbm",
                     data=training,
                     verbose=FALSE,
                     trControl=fitControl)

predictions.boost<-predict(modFit.boost,newdata=testing)

```

### GBM Confusion Matrix
```{r gbm confusion matrix}
confusionMatrix(predictions.boost,testing$classe)
```
          
```{r gbm model plot}
plot(modFit.boost)
```
### Running a Random Forest model against all features
```{r model fitting RF, include=FALSE}
# Train a model using RF
modFit.boost2<-train(classe~.,method="rf",
                     data=training,
                     verbose=FALSE,
                     trControl=fitControl)

predictions.boost2<-predict(modFit.boost2,newdata=testing)

```

### Randdom Forest Confustion Matrix
```{r rf confusion matrix}
# Cross-validated data
confusionMatrix(predictions.boost2,testing$classe)

```

```{r model printing RF}
plot(modFit.boost2)
```

```{r generate validation output}
validation$classe<-predict(modFit.boost,newdata=validation)

print(validation$classe)

write.csv(validation,file = "exprediction.csv")

validation$classe<-predict(modFit.boost2,newdata=validation)

print(validation$classe)

write.csv(validation,file="rfprediction.csv")



```
## Citation
Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.

Read more: <http://groupware.les.inf.puc-rio.br/har#weight_lifting_exercises#ixzz4aHsvXnQK>

### Useful links

[Preprocess method](https://www.rdocumentation.org/packages/caret/versions/6.0-73/topics/preProcess)

[Caret package](https://topepo.github.io/caret/model-training-and-tuning.html)